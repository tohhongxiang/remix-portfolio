<!DOCTYPE html><html lang="en" class=""><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>lAIs: Learn with AI! | THX</title><meta name="description" content="An AI Companion for students to study lectures more efficiently"/><meta name="color-scheme" content="dark light"/><script>
(() => {
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches
    ? 'light'
    : 'dark';
  
  const cl = document.documentElement.classList;
  const dataAttr = document.documentElement.dataset.theme;

  if (dataAttr != null) {
    const themeAlreadyApplied = dataAttr === 'light' || dataAttr === 'dark';
    if (!themeAlreadyApplied) {
      document.documentElement.dataset.theme = theme;
    }
  } else {
    const themeAlreadyApplied = cl.contains('light') || cl.contains('dark');
    if (!themeAlreadyApplied) {
      cl.add(theme);
    }
  }
  
  const meta = document.querySelector('meta[name=color-scheme]');
  if (meta) {
    if (theme === 'dark') {
      meta.content = 'dark light';
    } else if (theme === 'light') {
      meta.content = 'light dark';
    }
  }
})();
</script><link rel="stylesheet" href="/build/_assets/tailwind-I3A4NCC2.css"/></head><body class="relative bg-background"><div class="fixed right-2 top-2 z-30"><button class="inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-10 w-10 cursor-pointer" type="button" id="radix-:Rp:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun h-[1.2rem] w-[1.2rem] rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-moon absolute h-[1.2rem] w-[1.2rem] rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path></svg><span class="sr-only">Toggle theme</span></button></div><nav class="fixed left-0 top-0 z-10 flex w-full bg-background/80 px-4 py-4 backdrop-blur"><a class="flex items-center justify-start gap-2 px-2" href="/"><div class="relative"><div class="rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0"><img src="/images/navbar-logo.png" alt="" class="h-8 w-8 object-contain"/></div><div class="absolute top-1/2 -translate-y-1/2 rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100"><img src="/images/navbar-logo-dark.png" alt="" class="h-8 w-8 object-contain"/></div></div><span class="font-bold">THX</span></a></nav><div class="flex h-full flex-col pt-16"><div class="flex-1"><div class="h-full w-full px-6"><div class="mx-auto flex max-w-[80ch] flex-col gap-8 py-16"><h1 class="text-center text-4xl font-bold lg:text-5xl" style="view-transition-name:lais-title">lAIs: Learn with AI!</h1><p class="text-center text-muted-foreground" style="view-transition-name:lais-detailed-description">lAIs is a web-based tool that takes a URL of an uploaded video lecture (on YouTube), and generates a variety of outputs to supplement learning. Summaries, audio transcriptions, quiz questions and even a chat to clarify doubts!</p><div class="flex flex-wrap items-center justify-center gap-x-8 gap-y-2"><a href="https://github.com/tohhongxiang123/techfest-2024/tree/master" target="_blank" rel="noopener noreferrer" class="group flex items-center justify-center gap-x-2 rounded-md px-4 py-2 hover:bg-slate-300/30 dark:hover:bg-slate-800/30"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 fill-muted-foreground group-hover:fill-foreground"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="font-semibold text-muted-foreground group-hover:text-foreground">Github</span></a></div></div><div style="view-transition-name:lais-cover-image" class="mx-auto max-w-[80ch]"><div class="relative" role="region" aria-roledescription="carousel"><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rcp9:" data-state="closed" aria-label="Open image in a modal"><div class="overflow-hidden"><div class="flex -ml-4"><div role="group" aria-roledescription="slide" class="min-w-0 shrink-0 grow-0 basis-full pl-4"><img src="/project_screenshots/lais/thumbnail.jpg" alt="" class="aspect-video h-full w-full rounded-md object-contain" loading="eager"/></div><div role="group" aria-roledescription="slide" class="min-w-0 shrink-0 grow-0 basis-full pl-4"><img src="/project_screenshots/lais/image-1.jpg" alt="" class="aspect-video h-full w-full rounded-md object-contain" loading="lazy"/></div><div role="group" aria-roledescription="slide" class="min-w-0 shrink-0 grow-0 basis-full pl-4"><img src="/project_screenshots/lais/image-2.jpg" alt="" class="aspect-video h-full w-full rounded-md object-contain" loading="lazy"/></div><div role="group" aria-roledescription="slide" class="min-w-0 shrink-0 grow-0 basis-full pl-4"><img src="/project_screenshots/lais/image-3.jpg" alt="" class="aspect-video h-full w-full rounded-md object-contain" loading="lazy"/></div><div role="group" aria-roledescription="slide" class="min-w-0 shrink-0 grow-0 basis-full pl-4"><img src="/project_screenshots/lais/image-4.jpg" alt="" class="aspect-video h-full w-full rounded-md object-contain" loading="lazy"/></div></div></div></button><div class="relative flex items-center justify-center" role="group" aria-roledescription="carousel-controls"><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-8 w-8 rounded-full top-1/2 relative left-0 right-0 translate-y-0" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left h-4 w-4"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg><span class="sr-only">Previous slide</span></button><div class="flex items-center justify-center gap-x-4 p-6"></div><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-8 w-8 rounded-full top-1/2 relative left-0 right-0 translate-y-0" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-4 w-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg><span class="sr-only">Next slide</span></button></div></div></div><div class="prose mx-auto py-16 dark:prose-invert"><h2>Inspiration</h2>
<p>Lectures are long, and students often are unable to find the motivation to consume all the knowledge presented to them in one go, especially when the lectures are recorded and therefore easier to put away for later. As students ourselves, we envisioned a tool that could make taking the first steps in learning from recorded lectures much easier. lAIs was developed exactly for this, leveraging on AI to guide students towards quicker understanding of lecture materials by both improving intrinsic motivation, and providing real-time assistance in learning.</p>
<h2>What it does &amp; How does it work?</h2>
<p>lAIs is a web-based tool that takes a URL of an uploaded video lecture (on YouTube), and generates a variety of outputs to supplement learning.</p>
<ol>
<li>Take a Youtube URL and paste it in!</li>
<li>Confirm that the Youtube URL is correct.</li>
<li>View your generated content!</li>
</ol>
<h2>Features</h2>
<h3>(1) Transcription of recorded lecture</h3>
<p>An application of OpenAI Whisper to generate a transcript based on the voice recording in the lecture video.</p>
<h3>(2) Summary generation of entire transcription</h3>
<p>The generated transcript from (1) is then summarised with Meta’s LLaMa (Large Language Model Meta AI).
Key learning points are identified by the LLM based on the transcript, and are then consolidated into the summary of lecture content.</p>
<h3>(3) Generation of questions to reinforce learning</h3>
<p>Based on all content available from (1) and (2), sample questions to test learners’ understanding are generated with the same LLM.</p>
<h3>(4) Profbot</h3>
<p>Profbot, the AI assistant that has learnt the lecture content from your recorded lecture(s), and is more than willing to help clarify any doubts students may have while studying their actual resources.</p>
<p>Similar to (3), all available content is parsed through the same LLM to form a foundational knowledge base that will be tapped on to clarify doubts from the provided content. Questions are also processed with the LLM to generate responses based on knowledge gained from previous material.</p>
<h2>Why does it work?</h2>
<p>Motivation to initiate and/or commit to a task is often hindered by intrinsic barriers such as inertia and value expectancy. By simply reframing the goal of “sit through a 2-hour lecture recording” to “spend 5 minutes reading a summary before reading further”, lAIs significantly increases the expected value of the task by significantly reducing the time required to engage with lecture content. By encouraging students to take the first step in engaging with lecture content, students will find themselves with psychological momentum in the learning process, making the consumption of additional content less draining.</p>
<p>The use of an AI chatbot to clarify doubts is also essential to maintaining a high level of motivation - having doubts unanswered in real time often disrupts any momentum gained from earlier engagement, especially when understanding of topic 1 is a prerequisite to learning topic 2. Students no longer need to rely solely on emailing their tutors and waiting for a reply the next business day, and then needing to overcome any inertia to begin learning again.</p>
<h2>Impact and Unintended Consequences</h2>
<p>We envision lAIs to primarily aid students - anyone who is trying to learn new content. By making engagement with content easier, productivity of learners should be improved, along with a better quality of life as a result of time savings in the learning process.</p>
<p>Still, we can expect learners to treat this tool as a shortcut to skip the process of learning from long-form content. This ultimately is counter-productive, as all the necessary (and examinable) details delivered in a lecture must be obtained from proper study of materials. Students should be able to quickly learn that this form of usage of lAIs id detrimental to their learning, and should use it more as a complement to their learning.</p>
<p>Also, an over-reliance on the chatbot to clarify doubts could also limit the depth of understanding of the material, since the bot is only as intelligent as the source material. Any further insights that could be valuable but not discussed explicitly in the source material are naturally not offered by the bot, and therefore engaging with tutors directly is still a necessary part of this learning process. We still strongly believe that these AI tools are not meant to completely replace tutors, but to make learning more accessible and engaging.</p>
<p>An interesting potential group of users can be the tutors or professors themselves - instead of using lAIs as a learning tool as intended, it could be used as a benchmarking tool to evaluate the delivery of recorded lecture content. Since the AI generates a summary based on observed key pointers, tutors can then check to ensure that their delivery has emphasised all the crucial learning points sufficiently. Else, they could follow-up with learners to further emphasise the key learning points which were not delivered adequately.</p>
<p>Furthermore, the constant availability of a chatbot to clarify doubts on lecture content could also prompt tutors to recommend lAIs to their students to reduce the occurrences of emails asking to clarify doubts. This frees up more of their time, allowing them to engage more in extra-curricular activities such as conducting research. Of course, over-reliance on the bots can lead to shirking responsibility in terms of clarifying the doubts of learners, so it is up to the innate responsibility of tutors to manage the reliance on tools such as lAIs.</p>
<h2>Current Limitations</h2>
<p>Due to lAIs being a prototype, we observe the following limitations:</p>
<h3>Slow - running the LLM locally</h3>
<p>The prototype is limited by hardware due to LLM processes happening locally. We note that significant generation times can arise when handling very long videos, in addition to memory issues when generating a large transcript to be parsed through the LLM.</p>
<h3>Limited to YouTube URLs</h3>
<p>Due to timeline limitations, input material has been limited to only YouTube links.
The complexity involved in accepting other forms of video content, such as directly uploading .mp4 files from the user’s computer, made implementation of this feature less of a priority.</p>
<h3>Transcription quality (breaks, accuracy) varies depending on lecturer</h3>
<p>We observe varying degrees of success in Whisper’s ability to transcribe the video lecture content accurately due to variations in delivery such as speed and accents.
Since the full video transcription is the input for all other features of lAIs, the accuracy of this transcription is critical to the good performance of this tool. Issues with the source transcription will more than likely snowball and surface as issues with final outputs such as the summary, and responses given by the Profbot.</p>
<h3>Unable to keep track of previously generated content (user)</h3>
<p>Doing this requires implementation of a database, which was not a priority due to time concerns. This could be a useful feature, especially for learners who would like to review content in the future and not need to wait for the generation process every time the same video is uploaded.</p>
<h2>Accomplishments that we&#x27;re proud of</h2>
<ul>
<li>An well-polished MVP, which is responsive as well for both mobile and desktop users</li>
<li>First time successfully implementing Generative AI into a project</li>
</ul>
<h2>Challenges we ran into</h2>
<p>There were many challenges that we ran into, but the biggest ones were</p>
<ul>
<li>Getting LLaMa to produce consistent results was difficult. LLaMa was initially inconsistent in producing summaries and test questions, however after prompt engineering, it provided us with more consistent results.</li>
<li>NextJS 13 was not easy to use. Previously, we only used NextJS 12 for projects, and since NextJS 13 was out for awhile already, we decided to use it for this project. However, it proved to be more challenging than initially thought because of the amount of changes moving from NextJS 12 to NextJS 13, which caused many bugs.</li>
<li>Difficulties in combining the frontend and backend. Both the frontend and the backend were on 2 separate machines, and it was challenging to setup the communication between them.</li>
</ul>
<h2>What we learned</h2>
<ul>
<li>The effectiveness of implementing generative AIs into a project depends heavily on the prompts provided</li>
</ul>
<h2>What&#x27;s next for lAIs</h2>
<ul>
<li>User logins to allow users to access their previously generated summaries and test questions</li>
<li>Video-specific annotations for each user</li>
<li>Improved loading times</li>
<li>More robust chat features</li>
<li>Security features such as encryption</li>
<li>Real-time transcribing of lectures you are in</li>
<li>File uploads instead of just youtube videos</li>
</ul></div></div></div><footer class="flex flex-col items-end justify-between gap-4 border-t border-muted-foreground/25 p-4 sm:flex-row sm:items-center"><ul class="flex gap-4"><li><a href="https://github.com/tohhongxiang123" target="_blank" rel="noopener noreferrer"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 fill-muted-foreground transition-all duration-150 ease-in-out hover:rotate-3 hover:scale-105 hover:fill-foreground"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a></li><li><a href="https://www.linkedin.com/in/toh-hong-xiang/" target="_blank" rel="noopener noreferrer"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 fill-muted-foreground transition-all duration-150 ease-in-out hover:rotate-3 hover:scale-105 hover:fill-foreground"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a></li><li><a href="mailto:tohhongxiang@gmail.com" target="_blank" rel="noopener noreferrer"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 fill-muted-foreground transition-all duration-150 ease-in-out hover:rotate-3 hover:scale-105 hover:fill-foreground"><title>Gmail</title><path d="M24 5.457v13.909c0 .904-.732 1.636-1.636 1.636h-3.819V11.73L12 16.64l-6.545-4.91v9.273H1.636A1.636 1.636 0 0 1 0 19.366V5.457c0-2.023 2.309-3.178 3.927-1.964L5.455 4.64 12 9.548l6.545-4.91 1.528-1.145C21.69 2.28 24 3.434 24 5.457z"></path></svg></a></li></ul><p class="font-light text-muted-foreground">Toh Hong Xiang, 2024</p></footer></div><script>((STORAGE_KEY, restoreKey) => {
    if (!window.history.state || !window.history.state.key) {
      let key = Math.random().toString(32).slice(2);
      window.history.replaceState({
        key
      }, "");
    }
    try {
      let positions = JSON.parse(sessionStorage.getItem(STORAGE_KEY) || "{}");
      let storedY = positions[restoreKey || window.history.state.key];
      if (typeof storedY === "number") {
        window.scrollTo(0, storedY);
      }
    } catch (error) {
      console.error(error);
      sessionStorage.removeItem(STORAGE_KEY);
    }
  })("positions", null)</script><link rel="modulepreload" href="/build/manifest-21974987.js"/><link rel="modulepreload" href="/build/entry.client-S4TRE4UU.js"/><link rel="modulepreload" href="/build/_shared/chunk-XRKGASJW.js"/><link rel="modulepreload" href="/build/_shared/chunk-G5WX4PPA.js"/><link rel="modulepreload" href="/build/_shared/chunk-2U6YV2YJ.js"/><link rel="modulepreload" href="/build/_shared/chunk-GSQ7VZ5Q.js"/><link rel="modulepreload" href="/build/_shared/chunk-CF3TWL4R.js"/><link rel="modulepreload" href="/build/root-V623QUGS.js"/><link rel="modulepreload" href="/build/_shared/chunk-D2AQPTTR.js"/><link rel="modulepreload" href="/build/routes/projects-ZTHNSKLF.js"/><link rel="modulepreload" href="/build/_shared/chunk-FSMXE2QH.js"/><link rel="modulepreload" href="/build/routes/projects.$slug-PDELXZQA.js"/><script>window.__remixContext = {"url":"/projects/lais","state":{"loaderData":{"root":{"theme":null},"routes/projects.$slug":{"frontmatter":{"title":"lAIs: Learn with AI!","thumbnail":"/project_screenshots/lais/thumbnail.jpg","description":"An AI Companion for students to study lectures more efficiently","detailedDescription":"lAIs is a web-based tool that takes a URL of an uploaded video lecture (on YouTube), and generates a variety of outputs to supplement learning. Summaries, audio transcriptions, quiz questions and even a chat to clarify doubts!","githubLink":"https://github.com/tohhongxiang123/techfest-2024/tree/master","screenshots":["/project_screenshots/lais/image-1.jpg","/project_screenshots/lais/image-2.jpg","/project_screenshots/lais/image-3.jpg","/project_screenshots/lais/image-4.jpg"],"date":"Feb 2024"},"code":"var Component=(()=\u003e{var u=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var g=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var y=(n,e)=\u003e()=\u003e(e||n((e={exports:{}}).exports,e),e.exports),b=(n,e)=\u003e{for(var i in e)r(n,i,{get:e[i],enumerable:!0})},s=(n,e,i,a)=\u003e{if(e\u0026\u0026typeof e==\"object\"||typeof e==\"function\")for(let o of m(e))!f.call(n,o)\u0026\u0026o!==i\u0026\u0026r(n,o,{get:()=\u003ee[o],enumerable:!(a=p(e,o))||a.enumerable});return n};var w=(n,e,i)=\u003e(i=n!=null?u(g(n)):{},s(e||!n||!n.__esModule?r(i,\"default\",{value:n,enumerable:!0}):i,n)),v=n=\u003es(r({},\"__esModule\",{value:!0}),n);var c=y((I,l)=\u003e{l.exports=_jsx_runtime});var L={};b(L,{default:()=\u003ed,frontmatter:()=\u003ek});var t=w(c()),k={title:\"lAIs: Learn with AI!\",thumbnail:\"/project_screenshots/lais/thumbnail.jpg\",description:\"An AI Companion for students to study lectures more efficiently\",detailedDescription:\"lAIs is a web-based tool that takes a URL of an uploaded video lecture (on YouTube), and generates a variety of outputs to supplement learning. Summaries, audio transcriptions, quiz questions and even a chat to clarify doubts!\",githubLink:\"https://github.com/tohhongxiang123/techfest-2024/tree/master\",screenshots:[\"/project_screenshots/lais/image-1.jpg\",\"/project_screenshots/lais/image-2.jpg\",\"/project_screenshots/lais/image-3.jpg\",\"/project_screenshots/lais/image-4.jpg\"],date:\"Feb 2024\"};function h(n){let e={h2:\"h2\",h3:\"h3\",li:\"li\",ol:\"ol\",p:\"p\",ul:\"ul\",...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h2,{children:\"Inspiration\"}),`\n`,(0,t.jsx)(e.p,{children:\"Lectures are long, and students often are unable to find the motivation to consume all the knowledge presented to them in one go, especially when the lectures are recorded and therefore easier to put away for later. As students ourselves, we envisioned a tool that could make taking the first steps in learning from recorded lectures much easier. lAIs was developed exactly for this, leveraging on AI to guide students towards quicker understanding of lecture materials by both improving intrinsic motivation, and providing real-time assistance in learning.\"}),`\n`,(0,t.jsx)(e.h2,{children:\"What it does \u0026 How does it work?\"}),`\n`,(0,t.jsx)(e.p,{children:\"lAIs is a web-based tool that takes a URL of an uploaded video lecture (on YouTube), and generates a variety of outputs to supplement learning.\"}),`\n`,(0,t.jsxs)(e.ol,{children:[`\n`,(0,t.jsx)(e.li,{children:\"Take a Youtube URL and paste it in!\"}),`\n`,(0,t.jsx)(e.li,{children:\"Confirm that the Youtube URL is correct.\"}),`\n`,(0,t.jsx)(e.li,{children:\"View your generated content!\"}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{children:\"Features\"}),`\n`,(0,t.jsx)(e.h3,{children:\"(1) Transcription of recorded lecture\"}),`\n`,(0,t.jsx)(e.p,{children:\"An application of OpenAI Whisper to generate a transcript based on the voice recording in the lecture video.\"}),`\n`,(0,t.jsx)(e.h3,{children:\"(2) Summary generation of entire transcription\"}),`\n`,(0,t.jsx)(e.p,{children:`The generated transcript from (1) is then summarised with Meta\\u2019s LLaMa (Large Language Model Meta AI).\nKey learning points are identified by the LLM based on the transcript, and are then consolidated into the summary of lecture content.`}),`\n`,(0,t.jsx)(e.h3,{children:\"(3) Generation of questions to reinforce learning\"}),`\n`,(0,t.jsx)(e.p,{children:\"Based on all content available from (1) and (2), sample questions to test learners\\u2019 understanding are generated with the same LLM.\"}),`\n`,(0,t.jsx)(e.h3,{children:\"(4) Profbot\"}),`\n`,(0,t.jsx)(e.p,{children:\"Profbot, the AI assistant that has learnt the lecture content from your recorded lecture(s), and is more than willing to help clarify any doubts students may have while studying their actual resources.\"}),`\n`,(0,t.jsx)(e.p,{children:\"Similar to (3), all available content is parsed through the same LLM to form a foundational knowledge base that will be tapped on to clarify doubts from the provided content. Questions are also processed with the LLM to generate responses based on knowledge gained from previous material.\"}),`\n`,(0,t.jsx)(e.h2,{children:\"Why does it work?\"}),`\n`,(0,t.jsx)(e.p,{children:\"Motivation to initiate and/or commit to a task is often hindered by intrinsic barriers such as inertia and value expectancy. By simply reframing the goal of \\u201Csit through a 2-hour lecture recording\\u201D to \\u201Cspend 5 minutes reading a summary before reading further\\u201D, lAIs significantly increases the expected value of the task by significantly reducing the time required to engage with lecture content. By encouraging students to take the first step in engaging with lecture content, students will find themselves with psychological momentum in the learning process, making the consumption of additional content less draining.\"}),`\n`,(0,t.jsx)(e.p,{children:\"The use of an AI chatbot to clarify doubts is also essential to maintaining a high level of motivation - having doubts unanswered in real time often disrupts any momentum gained from earlier engagement, especially when understanding of topic 1 is a prerequisite to learning topic 2. Students no longer need to rely solely on emailing their tutors and waiting for a reply the next business day, and then needing to overcome any inertia to begin learning again.\"}),`\n`,(0,t.jsx)(e.h2,{children:\"Impact and Unintended Consequences\"}),`\n`,(0,t.jsx)(e.p,{children:\"We envision lAIs to primarily aid students - anyone who is trying to learn new content. By making engagement with content easier, productivity of learners should be improved, along with a better quality of life as a result of time savings in the learning process.\"}),`\n`,(0,t.jsx)(e.p,{children:\"Still, we can expect learners to treat this tool as a shortcut to skip the process of learning from long-form content. This ultimately is counter-productive, as all the necessary (and examinable) details delivered in a lecture must be obtained from proper study of materials. Students should be able to quickly learn that this form of usage of lAIs id detrimental to their learning, and should use it more as a complement to their learning.\"}),`\n`,(0,t.jsx)(e.p,{children:\"Also, an over-reliance on the chatbot to clarify doubts could also limit the depth of understanding of the material, since the bot is only as intelligent as the source material. Any further insights that could be valuable but not discussed explicitly in the source material are naturally not offered by the bot, and therefore engaging with tutors directly is still a necessary part of this learning process. We still strongly believe that these AI tools are not meant to completely replace tutors, but to make learning more accessible and engaging.\"}),`\n`,(0,t.jsx)(e.p,{children:\"An interesting potential group of users can be the tutors or professors themselves - instead of using lAIs as a learning tool as intended, it could be used as a benchmarking tool to evaluate the delivery of recorded lecture content. Since the AI generates a summary based on observed key pointers, tutors can then check to ensure that their delivery has emphasised all the crucial learning points sufficiently. Else, they could follow-up with learners to further emphasise the key learning points which were not delivered adequately.\"}),`\n`,(0,t.jsx)(e.p,{children:\"Furthermore, the constant availability of a chatbot to clarify doubts on lecture content could also prompt tutors to recommend lAIs to their students to reduce the occurrences of emails asking to clarify doubts. This frees up more of their time, allowing them to engage more in extra-curricular activities such as conducting research. Of course, over-reliance on the bots can lead to shirking responsibility in terms of clarifying the doubts of learners, so it is up to the innate responsibility of tutors to manage the reliance on tools such as lAIs.\"}),`\n`,(0,t.jsx)(e.h2,{children:\"Current Limitations\"}),`\n`,(0,t.jsx)(e.p,{children:\"Due to lAIs being a prototype, we observe the following limitations:\"}),`\n`,(0,t.jsx)(e.h3,{children:\"Slow - running the LLM locally\"}),`\n`,(0,t.jsx)(e.p,{children:\"The prototype is limited by hardware due to LLM processes happening locally. We note that significant generation times can arise when handling very long videos, in addition to memory issues when generating a large transcript to be parsed through the LLM.\"}),`\n`,(0,t.jsx)(e.h3,{children:\"Limited to YouTube URLs\"}),`\n`,(0,t.jsx)(e.p,{children:`Due to timeline limitations, input material has been limited to only YouTube links.\nThe complexity involved in accepting other forms of video content, such as directly uploading .mp4 files from the user\\u2019s computer, made implementation of this feature less of a priority.`}),`\n`,(0,t.jsx)(e.h3,{children:\"Transcription quality (breaks, accuracy) varies depending on lecturer\"}),`\n`,(0,t.jsx)(e.p,{children:`We observe varying degrees of success in Whisper\\u2019s ability to transcribe the video lecture content accurately due to variations in delivery such as speed and accents.\nSince the full video transcription is the input for all other features of lAIs, the accuracy of this transcription is critical to the good performance of this tool. Issues with the source transcription will more than likely snowball and surface as issues with final outputs such as the summary, and responses given by the Profbot.`}),`\n`,(0,t.jsx)(e.h3,{children:\"Unable to keep track of previously generated content (user)\"}),`\n`,(0,t.jsx)(e.p,{children:\"Doing this requires implementation of a database, which was not a priority due to time concerns. This could be a useful feature, especially for learners who would like to review content in the future and not need to wait for the generation process every time the same video is uploaded.\"}),`\n`,(0,t.jsx)(e.h2,{children:\"Accomplishments that we're proud of\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"An well-polished MVP, which is responsive as well for both mobile and desktop users\"}),`\n`,(0,t.jsx)(e.li,{children:\"First time successfully implementing Generative AI into a project\"}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{children:\"Challenges we ran into\"}),`\n`,(0,t.jsx)(e.p,{children:\"There were many challenges that we ran into, but the biggest ones were\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"Getting LLaMa to produce consistent results was difficult. LLaMa was initially inconsistent in producing summaries and test questions, however after prompt engineering, it provided us with more consistent results.\"}),`\n`,(0,t.jsx)(e.li,{children:\"NextJS 13 was not easy to use. Previously, we only used NextJS 12 for projects, and since NextJS 13 was out for awhile already, we decided to use it for this project. However, it proved to be more challenging than initially thought because of the amount of changes moving from NextJS 12 to NextJS 13, which caused many bugs.\"}),`\n`,(0,t.jsx)(e.li,{children:\"Difficulties in combining the frontend and backend. Both the frontend and the backend were on 2 separate machines, and it was challenging to setup the communication between them.\"}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{children:\"What we learned\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"The effectiveness of implementing generative AIs into a project depends heavily on the prompts provided\"}),`\n`]}),`\n`,(0,t.jsx)(e.h2,{children:\"What's next for lAIs\"}),`\n`,(0,t.jsxs)(e.ul,{children:[`\n`,(0,t.jsx)(e.li,{children:\"User logins to allow users to access their previously generated summaries and test questions\"}),`\n`,(0,t.jsx)(e.li,{children:\"Video-specific annotations for each user\"}),`\n`,(0,t.jsx)(e.li,{children:\"Improved loading times\"}),`\n`,(0,t.jsx)(e.li,{children:\"More robust chat features\"}),`\n`,(0,t.jsx)(e.li,{children:\"Security features such as encryption\"}),`\n`,(0,t.jsx)(e.li,{children:\"Real-time transcribing of lectures you are in\"}),`\n`,(0,t.jsx)(e.li,{children:\"File uploads instead of just youtube videos\"}),`\n`]})]})}function d(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(h,{...n})}):h(n)}return v(L);})();\n;return Component;","slug":"lais"},"routes/projects":null},"actionData":null,"errors":null},"future":{"v3_fetcherPersist":false,"v3_relativeSplatPath":false,"v3_throwAbortReason":false}};</script><script type="module" async="">import "/build/manifest-21974987.js";
import * as route0 from "/build/root-V623QUGS.js";
import * as route1 from "/build/routes/projects-ZTHNSKLF.js";
import * as route2 from "/build/routes/projects.$slug-PDELXZQA.js";
window.__remixRouteModules = {"root":route0,"routes/projects":route1,"routes/projects.$slug":route2};

import("/build/entry.client-S4TRE4UU.js");</script></body></html>